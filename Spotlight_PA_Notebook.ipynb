{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9fa72c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abc1db8",
   "metadata": {},
   "source": [
    "# Spotlight PA Demonstration\n",
    "\n",
    "Note: This notebook will accompany the Case Study #1 article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d57681b",
   "metadata": {},
   "source": [
    "## Download Relevant Data\n",
    "\n",
    "[Data Set #1 (without prisoner reallocation)](https://redistrictingdatahub.org/dataset/pennsylvania-block-pl-94-171-2020-official-without-prisoner-reallocation/)\n",
    "- Note: This dataset was used for congressional redistricting\n",
    "\n",
    "[Data Set #2 (with prisoner reallocation)](https://redistrictingdatahub.org/dataset/pennsylvania-block-pl-94-171-2020-official-prison-adjusted/)\n",
    "- Note: This dataset was used for state legislative redistricting\n",
    "\n",
    "[2020 PA L2 Voterfile Data on P.L. Block Geographies](https://redistrictingdatahub.org/dataset/2021-pennsylvania-l2-voter-file-aggregated-to-2020-census-blocks/), [by table](https://redistrictingdatahub.org/dataset/pennsylvania-block-pl-94171-2020-by-table/)\n",
    "- Note: This dataset will be used to get party-registration data for each district\n",
    "\n",
    "[2020 Census Block-Level Data](https://redistrictingdatahub.org/dataset/pennsylvania-block-pl-94171-2020/)\n",
    "- Note: This dataset will be used for the block-assignments for the old districts and for demographic data for the congressional districts. For state legislative districts, we'll use the prisoner reallocated data allocated to the old district geometries\n",
    "- You should download the .csv version of this file\n",
    "- I renamed the folder \"pa_pl2020_b_csv\" to distinguish from the below file\n",
    "\n",
    "[2020 Census Block-Level Data](https://redistrictingdatahub.org/dataset/pennsylvania-block-pl-94171-2020-by-table/)\n",
    "- Note: This is a smaller version of the above dataset. We use this smaller version to grab the shapefile and demographic data for PA.\n",
    "- You should download the .shp version of this file\n",
    "\n",
    "[New State House District Block-Assignment File](https://davesredistricting.org/maps#state::PA)  \n",
    "[New State Senate District Block-Assignment File](https://davesredistricting.org/maps#state::PA)  \n",
    "[New Congressional District Block-Assignment File](https://davesredistricting.org/maps#state::PA) \n",
    "- Note: For these files, you'll need to have an account with DRA. Navigate to each of the three links above, and open up each of the three official maps. On each map, click the arrow pointing to the upper-right, check \"Export alternate census blocks\" and export the block assignment files. \n",
    "- For the purposes of folder structure, I've renamed these files, block-assignment-pa-sldl, block-assignment-pa-sldu, and block-assignment-pa-cong respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8156900a",
   "metadata": {},
   "source": [
    "In whatever directory you are working in, creating a folder named \"raw-from-source\" and put the above files in them. For any zipped files (the first four in the above list) you should unzip them\n",
    "\n",
    "After making the name changes to the block-assignment files (being sure to rename the right files), you should have a \"raw-from-source\" folder with the following files / folders:\n",
    "\n",
    "- block-assignments-pa-cong.csv\n",
    "- block-assignments-pa-sldl.csv\n",
    "- block-assignments-pa-sldu.csv\n",
    "- PA_L2_2020BlockAgg\n",
    "- pa_pl2020_b\n",
    "- pa_pl2020_b_csv\n",
    "- pa_pl2020_block_noreallocation\n",
    "- pa_pl2020_official_blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144fe8e3",
   "metadata": {},
   "source": [
    "## Load in Relevant Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae650899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1t/0q4w6hm92mg_zxd84dfxmq3m0000gn/T/ipykernel_30446/3404305616.py:13: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pa_pl_census_csv = pd.read_csv(\"./raw-from-source/pa_pl2020_b_csv/pa_pl2020_b.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Load the block assignment files\n",
    "cong_baf = pd.read_csv(\"./raw-from-source/block-assignments-pa-cong.csv\")\n",
    "sldl_baf = pd.read_csv(\"./raw-from-source/block-assignments-pa-sldl.csv\")\n",
    "sldu_baf = pd.read_csv(\"./raw-from-source/block-assignments-pa-sldu.csv\")\n",
    "\n",
    "# Load the voter file data\n",
    "pa_voterfile = pd.read_csv(\"./raw-from-source/PA_L2_2020BlockAgg/PA_l2_2020block_agg_20210902.csv\")\n",
    "\n",
    "# Load in the P2 table of the PL data\n",
    "pa_pl_census = gp.read_file(\"./raw-from-source/pa_pl2020_b/pa_pl2020_p2_b.shp\")\n",
    "\n",
    "# Load in the csv version of the PL data\n",
    "pa_pl_census_csv = pd.read_csv(\"./raw-from-source/pa_pl2020_b_csv/pa_pl2020_b.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b62be85",
   "metadata": {},
   "source": [
    "### Join the PL Data Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0bf9d0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1t/0q4w6hm92mg_zxd84dfxmq3m0000gn/T/ipykernel_30446/1318649540.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pa_pl_census_csv.rename(columns = {\"GEOCODE\":\"GEOID20\"}, inplace = True)\n",
      "/var/folders/1t/0q4w6hm92mg_zxd84dfxmq3m0000gn/T/ipykernel_30446/1318649540.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pa_pl_census_csv[\"GEOID20\"] = pa_pl_census_csv[\"GEOID20\"].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# Filter the PL csv to the needed columns\n",
    "pa_pl_census_csv = pa_pl_census_csv[[\"GEOCODE\", \"CD116\", \"SLDL18\", \"SLDU18\"]]\n",
    "\n",
    "# Rename the GEOCODE column to match the other PL file\n",
    "pa_pl_census_csv.rename(columns = {\"GEOCODE\":\"GEOID20\"}, inplace = True)\n",
    "\n",
    "# Change the column type to match the other PL file\n",
    "pa_pl_census_csv[\"GEOID20\"] = pa_pl_census_csv[\"GEOID20\"].astype(str)\n",
    "\n",
    "# Join the two files together\n",
    "pa_pl_census = gp.GeoDataFrame(pd.merge(pa_pl_census_csv, pa_pl_census, how = \"inner\", on = \"GEOID20\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ef7cd1",
   "metadata": {},
   "source": [
    "## Look into differences with PA's modified file\n",
    "\n",
    "Note: We exported the modified census blocks for all the block assignment files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cc47579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336985\n",
      "337039\n",
      "53\n",
      "107\n"
     ]
    }
   ],
   "source": [
    "# Cast the GEOCODE to string to match the baf\n",
    "pa_pl_census[\"GEOID20\"] = pa_pl_census[\"GEOID20\"].astype(str)\n",
    "\n",
    "# Notice that there are 54 more census blocks in PA's modified file\n",
    "print(pa_pl_census.shape[0])\n",
    "print(cong_baf.shape[0])\n",
    "\n",
    "# There are 53 census blocks that are only in the PL file and 107 blocks only in the modified file\n",
    "print(len(set(pa_pl_census[\"GEOID20\"]) - set(cong_baf[\"GEOID20\"])))\n",
    "print(len(set(cong_baf[\"GEOID20\"]) - set(pa_pl_census[\"GEOID20\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c68f04",
   "metadata": {},
   "source": [
    "If you take a closer look, you can see that 52 of the 53 blocks are split into \"a\" and \"b\" parts and 1 block is split into an \"a\", \"b\" and a \"c\".  \n",
    "\n",
    "For a total of 52 * 2 + 1 * 3 = 107 blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c68258b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'420912003017006',\n",
       " '420912003017026',\n",
       " '420912003017031',\n",
       " '420912003072001',\n",
       " '420912003072002',\n",
       " '420912003092014',\n",
       " '420912005073006',\n",
       " '420912016072017',\n",
       " '420912018001015',\n",
       " '420912019024010',\n",
       " '420912025002022',\n",
       " '420912026022000',\n",
       " '420912032032025',\n",
       " '420912033021010',\n",
       " '420912033022003',\n",
       " '420912033022010',\n",
       " '420912033022019',\n",
       " '420912033022021',\n",
       " '420912033022024',\n",
       " '420912033022027',\n",
       " '420912033031001',\n",
       " '420912049003011',\n",
       " '420912061041008',\n",
       " '420912061042001',\n",
       " '420912061062006',\n",
       " '420912061062010',\n",
       " '420912061062012',\n",
       " '420912078002001',\n",
       " '420912078002002',\n",
       " '420912078002003',\n",
       " '420912078002004',\n",
       " '420912078002006',\n",
       " '420912078003020',\n",
       " '420912078004002',\n",
       " '420912078004030',\n",
       " '420912078004037',\n",
       " '420912086041002',\n",
       " '420912087041000',\n",
       " '420912105003007',\n",
       " '420912105003010',\n",
       " '421010119002007',\n",
       " '421010207011002',\n",
       " '421010207011009',\n",
       " '421010207012008',\n",
       " '421010255001004',\n",
       " '421010257002008',\n",
       " '421010341003001',\n",
       " '421019804001000',\n",
       " '421019809011000',\n",
       " '421019809011005',\n",
       " '421019809011007',\n",
       " '421019809013009',\n",
       " '421019809013016'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(pa_pl_census[\"GEOID20\"]) - set(cong_baf[\"GEOID20\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a18017cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'420912003017006A',\n",
       " '420912003017006B',\n",
       " '420912003017026A',\n",
       " '420912003017026B',\n",
       " '420912003017031A',\n",
       " '420912003017031B',\n",
       " '420912003072001A',\n",
       " '420912003072001B',\n",
       " '420912003072002A',\n",
       " '420912003072002B',\n",
       " '420912003092014A',\n",
       " '420912003092014B',\n",
       " '420912005073006A',\n",
       " '420912005073006B',\n",
       " '420912016072017A',\n",
       " '420912016072017B',\n",
       " '420912018001015A',\n",
       " '420912018001015B',\n",
       " '420912019024010A',\n",
       " '420912019024010B',\n",
       " '420912025002022A',\n",
       " '420912025002022B',\n",
       " '420912026022000A',\n",
       " '420912026022000B',\n",
       " '420912032032025A',\n",
       " '420912032032025B',\n",
       " '420912033021010A',\n",
       " '420912033021010B',\n",
       " '420912033022003A',\n",
       " '420912033022003B',\n",
       " '420912033022010A',\n",
       " '420912033022010B',\n",
       " '420912033022019A',\n",
       " '420912033022019B',\n",
       " '420912033022021A',\n",
       " '420912033022021B',\n",
       " '420912033022024A',\n",
       " '420912033022024B',\n",
       " '420912033022027A',\n",
       " '420912033022027B',\n",
       " '420912033031001A',\n",
       " '420912033031001B',\n",
       " '420912049003011A',\n",
       " '420912049003011B',\n",
       " '420912061041008A',\n",
       " '420912061041008B',\n",
       " '420912061042001A',\n",
       " '420912061042001B',\n",
       " '420912061062006A',\n",
       " '420912061062006B',\n",
       " '420912061062010A',\n",
       " '420912061062010B',\n",
       " '420912061062012A',\n",
       " '420912061062012B',\n",
       " '420912078002001A',\n",
       " '420912078002001B',\n",
       " '420912078002002A',\n",
       " '420912078002002B',\n",
       " '420912078002003A',\n",
       " '420912078002003B',\n",
       " '420912078002004A',\n",
       " '420912078002004B',\n",
       " '420912078002006A',\n",
       " '420912078002006B',\n",
       " '420912078003020A',\n",
       " '420912078003020B',\n",
       " '420912078004002A',\n",
       " '420912078004002B',\n",
       " '420912078004030A',\n",
       " '420912078004030B',\n",
       " '420912078004037A',\n",
       " '420912078004037B',\n",
       " '420912086041002A',\n",
       " '420912086041002B',\n",
       " '420912087041000A',\n",
       " '420912087041000B',\n",
       " '420912087041000C',\n",
       " '420912105003007A',\n",
       " '420912105003007B',\n",
       " '420912105003010A',\n",
       " '420912105003010B',\n",
       " '421010119002007A',\n",
       " '421010119002007B',\n",
       " '421010207011002A',\n",
       " '421010207011002B',\n",
       " '421010207011009A',\n",
       " '421010207011009B',\n",
       " '421010207012008A',\n",
       " '421010207012008B',\n",
       " '421010255001004A',\n",
       " '421010255001004B',\n",
       " '421010257002008A',\n",
       " '421010257002008B',\n",
       " '421010341003001A',\n",
       " '421010341003001B',\n",
       " '421019804001000A',\n",
       " '421019804001000B',\n",
       " '421019809011000A',\n",
       " '421019809011000B',\n",
       " '421019809011005A',\n",
       " '421019809011005B',\n",
       " '421019809011007A',\n",
       " '421019809011007B',\n",
       " '421019809013009A',\n",
       " '421019809013009B',\n",
       " '421019809013016A',\n",
       " '421019809013016B'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(cong_baf[\"GEOID20\"]) - set(pa_pl_census[\"GEOID20\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ee894c",
   "metadata": {},
   "source": [
    "For each of the block assignment files, confirm that these split blocks are drawn into the same district. If this is the case, because we aggregating the data, we can \"combine\" the blocks and undo the split for the purposes of this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08e52754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in a column with the length of the GEOID\n",
    "cong_baf[\"id_len\"] = cong_baf[\"GEOID20\"].apply(lambda x: len(x))\n",
    "sldl_baf[\"id_len\"] = sldl_baf[\"GEOID20\"].apply(lambda x: len(x))\n",
    "sldu_baf[\"id_len\"] = sldu_baf[\"GEOID20\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2931279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15    336932\n",
      "16       107\n",
      "Name: id_len, dtype: int64\n",
      "15    336932\n",
      "16       107\n",
      "Name: id_len, dtype: int64\n",
      "15    336932\n",
      "16       107\n",
      "Name: id_len, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# As you can see, these are the 107 blocks\n",
    "print(cong_baf[\"id_len\"].value_counts())\n",
    "print(sldl_baf[\"id_len\"].value_counts())\n",
    "print(sldu_baf[\"id_len\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e1ada5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_block_ids = list(set(cong_baf[\"GEOID20\"]) - set(pa_pl_census[\"GEOID20\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "741791b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run code to check if there are any differing assignments for these blocks\n",
    "for block_id in split_block_ids:\n",
    "    '''\n",
    "    Filtering the baf to those blocks involved in the split and seeing how many unique district values\n",
    "    those blocks have, if there is more than one, print something out highlighting that block\n",
    "    '''\n",
    "    if cong_baf[cong_baf[\"GEOID20\"].str.contains(block_id[:len(block_id)-1])][\"District\"].value_counts().shape[0] != 1:\n",
    "        print(\"Split involving\", block_id, \"for the congressional map\")\n",
    "    if sldl_baf[sldl_baf[\"GEOID20\"].str.contains(block_id[:len(block_id)-1])][\"District\"].value_counts().shape[0] != 1:\n",
    "        print(\"Split involving\", block_id, \"for the state house map\")\n",
    "    if sldu_baf[sldu_baf[\"GEOID20\"].str.contains(block_id[:len(block_id)-1])][\"District\"].value_counts().shape[0] != 1:\n",
    "        print(\"Split involving\", block_id, \"for the state senate map\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6201eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit the block assignment files to combine the split blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1aaff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_baf[\"GEOID20\"] = cong_baf[\"GEOID20\"].str[0:15]\n",
    "cong_baf.drop_duplicates(inplace = True)\n",
    "\n",
    "sldl_baf[\"GEOID20\"] = sldl_baf[\"GEOID20\"].str[0:15]\n",
    "sldl_baf.drop_duplicates(inplace = True)\n",
    "\n",
    "sldu_baf[\"GEOID20\"] = sldu_baf[\"GEOID20\"].str[0:15]\n",
    "sldu_baf.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "455110ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_baf_dict = dict(zip(cong_baf[\"GEOID20\"], cong_baf[\"District\"]))\n",
    "sldl_baf_dict = dict(zip(sldl_baf[\"GEOID20\"], sldl_baf[\"District\"]))\n",
    "sldu_baf_dict = dict(zip(sldu_baf[\"GEOID20\"], sldu_baf[\"District\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6817c562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there are no changes to the census data in PA's modified, unre-allocated data, we don't need to use that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc07261b",
   "metadata": {},
   "source": [
    "## Clean the voterfile data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5dc52ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           geoid20  total_reg  age_18_19  age_20_24  age_25_29  age_30_34  \\\n",
      "0  420010314014003        134          1          4          6          8   \n",
      "1  420034803001010         52          1          4          2          5   \n",
      "2  420034801014003        105          1          8          4          7   \n",
      "3  420034315003011        229          0         15         11         26   \n",
      "4  420035190002007         53          0          3          2          4   \n",
      "\n",
      "   age_35_44  age_45_54  age_55_64  age_65_74  ...  p20140520  g20131105  \\\n",
      "0         17         13         28         39  ...         20         36   \n",
      "1          6         10          4          8  ...         13         17   \n",
      "2         20         18          9         16  ...          5          4   \n",
      "3         30         17         45         44  ...         35         37   \n",
      "4          5          5          5         14  ...          3          7   \n",
      "\n",
      "   p20130521  g20121106  pp20120424  p20120424  g20111108  p20110517  \\\n",
      "0         20         68          24         24         33         27   \n",
      "1         12         35          11         11         18         17   \n",
      "2          5         54           7          7         17          7   \n",
      "3         36        136          44         44         46         51   \n",
      "4          7         45           9          9         20         11   \n",
      "\n",
      "   g20101102  p20100518  \n",
      "0         52         27  \n",
      "1         21         16  \n",
      "2         32         12  \n",
      "3         89         43  \n",
      "4         33         17  \n",
      "\n",
      "[5 rows x 88 columns]\n",
      "270345\n",
      "Index(['geoid20', 'total_reg', 'age_18_19', 'age_20_24', 'age_25_29',\n",
      "       'age_30_34', 'age_35_44', 'age_45_54', 'age_55_64', 'age_65_74',\n",
      "       'age_75_84', 'age_85over', 'party_dem', 'party_rep', 'party_npp',\n",
      "       'party_rin', 'party_lib', 'party_grn', 'party_con', 'party_ind',\n",
      "       'party_oth', 'party_unk', 'eth1_eur', 'eth1_hisp', 'eth1_aa',\n",
      "       'eth1_esa', 'eth1_oth', 'eth1_unk', 'eth2_euro', 'eth2_93', 'eth2_64',\n",
      "       'eth2_34', 'eth2_23', 'eth2_30', 'eth2_10', 'eth2_21', 'eth2_14',\n",
      "       'eth2_61', 'eth2_55', 'eth2_12', 'eth2_35', 'eth2_59', 'eth2_85',\n",
      "       'eth2_38', 'eth2_66', 'eth2_29', 'eth2_32', 'eth2_33', 'eth2_13',\n",
      "       'eth2_99', 'eth2_26', 'eth2_57', 'eth2_19', 'eth2_15', 'eth2_81',\n",
      "       'eth2_unk', 'p20210518', 'g20201103', 'pp20200602', 'p20200602',\n",
      "       's20200317', 's20200225', 's20200114', 'g20191105', 's20190820',\n",
      "       'p20190521', 's20190402', 's20190312', 'g20181106', 'p20180515',\n",
      "       'g20171107', 'p20170516', 'g20161108', 'pp20160426', 'p20160426',\n",
      "       'g20151103', 'p20150519', 'g20141104', 'p20140520', 'g20131105',\n",
      "       'p20130521', 'g20121106', 'pp20120424', 'p20120424', 'g20111108',\n",
      "       'p20110517', 'g20101102', 'p20100518'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the voterfile data and filter to needed columns\n",
    "print(pa_voterfile.head())\n",
    "\n",
    "# Note there are a good deal of blocks not in the file, (because they don't have a registered voter)\n",
    "print(pa_voterfile.shape[0])\n",
    "\n",
    "# Filter the voterfile down to the columns we are interested in\n",
    "print(pa_voterfile.columns)\n",
    "\n",
    "# We will need the geoid column to join the data, and then the dem, rep, and total registration data\n",
    "pa_voterfile = pa_voterfile[['geoid20','total_reg', 'party_dem', 'party_rep']]\n",
    "\n",
    "# Rename the GEOID20 columns to match the others\n",
    "pa_voterfile.rename(columns={'geoid20':'GEOID20'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5f8c289",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_voterfile[\"GEOID20\"] = pa_voterfile[\"GEOID20\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811edbc8",
   "metadata": {},
   "source": [
    "## Clean the demographic data\n",
    "\n",
    "From their tool, it looks like Spotlight is tracking asian, black, hispanic, white, mixed race, and other as their racial / ethnic demographic categories\n",
    "\n",
    "If you look at our [Fields and Description](https://redistrictingdatahub.org/data/about-our-data/pl-94171-dataset/fields-and-descriptions/) page, you can see the relevant columns for this data\n",
    "- P0020001: Total population\n",
    "- P0020008: Asian (Non-hispanic)\n",
    "- P0020006: Black or African American alone (Non-hispanic)\n",
    "- P0020002: Hispanic or Latino\n",
    "- P0020005: White alone (Non-hispanic)\n",
    "- P0020011: Two or more races (Non-hispanic)\n",
    "\n",
    "Note: For the \"other\" category, we'll subtract the other categories from the total population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8c67544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list with the needed columns\n",
    "demo_columns = ['P0020001', 'P0020008', 'P0020006', 'P0020002', 'P0020005', 'P0020011']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "009509bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the pl census file\n",
    "pa_pl_census = gp.GeoDataFrame(pa_pl_census[[\"GEOID20\", \"CD116\", \"SLDL18\", \"SLDU18\"] + demo_columns + [\"geometry\"]].copy(deep = True))\n",
    "\n",
    "# Filter PA's modified census dataframes\n",
    "#pa_mod_reall = pa_mod_reall[[\"GEOID20\"] + demo_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20f8babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the voterfile to the two dataframes\n",
    "joined_pl_data = pd.merge(pa_pl_census, pa_voterfile, how = \"outer\", on = \"GEOID20\", indicator = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c6d353a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "both          270345\n",
       "left_only      66640\n",
       "right_only         0\n",
       "Name: _merge, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_pl_data[\"_merge\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "384bd000",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_pl_data[\"new_cong\"] = joined_pl_data[\"GEOID20\"].map(cong_baf_dict).fillna(\"N/A\")\n",
    "joined_pl_data[\"new_sldl\"] = joined_pl_data[\"GEOID20\"].map(sldl_baf_dict).fillna(\"N/A\")\n",
    "joined_pl_data[\"new_sldu\"] = joined_pl_data[\"GEOID20\"].map(sldu_baf_dict).fillna(\"N/A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744cef5f",
   "metadata": {},
   "source": [
    "## Add the prisoner-adjusted data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21b2ece8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15    336932\n",
      "16       107\n",
      "Name: id_len, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "420912087041000    3\n",
       "420912086041002    2\n",
       "420912061062012    2\n",
       "420912061062006    2\n",
       "421019809013009    2\n",
       "                  ..\n",
       "421330208013018    1\n",
       "420410124002044    1\n",
       "420410121001004    1\n",
       "420410103001037    1\n",
       "421010286003015    1\n",
       "Name: GEOID20, Length: 336985, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the data\n",
    "pa_mod_reall = gp.read_file(\"./raw-from-source/pa_pl2020_official_blocks/WP_Blocks.shp\")\n",
    "\n",
    "# Make a list of the columns needed \n",
    "reall_columns = ['P0010001', 'P0020008', 'P0020006', 'P0020002', 'P0020005', 'P0020011']\n",
    "\n",
    "# Filter down to the needed columns\n",
    "pa_mod_reall = pa_mod_reall[[\"GEOID20\"] + reall_columns].copy(deep = True)\n",
    "\n",
    "# Create a column related to the length of the GEOID column\n",
    "pa_mod_reall[\"id_len\"] = pa_mod_reall[\"GEOID20\"].apply(lambda x: len(x))\n",
    "\n",
    "# Expecting 107 blocks with a length of 16\n",
    "print(pa_mod_reall[\"id_len\"].value_counts())\n",
    "\n",
    "# Edit the GEOID20 file to clean the splits\n",
    "pa_mod_reall[\"GEOID20\"] = pa_mod_reall[\"GEOID20\"].str[0:15]\n",
    "\n",
    "# Expecting some duplicates here\n",
    "pa_mod_reall[\"GEOID20\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e3466c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the data to the PL blocks\n",
    "pa_mod_reall_cleaned = pa_mod_reall.groupby(\"GEOID20\").sum()\n",
    "\n",
    "# Clean the indices\n",
    "pa_mod_reall_cleaned.reset_index(inplace = True, drop = False)\n",
    "\n",
    "# Create a dictionary to rename the columns\n",
    "reall_dict = {i: i+\"_adj\" for i in reall_columns}\n",
    "\n",
    "# Rename the columns\n",
    "pa_mod_reall_cleaned.rename(columns=reall_dict, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9458f6",
   "metadata": {},
   "source": [
    "### Join the Prisoner-Adjusted Data to the Other DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22478b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the merge column\n",
    "joined_pl_data.drop(\"_merge\", axis = 1, inplace = True)\n",
    "\n",
    "# Join the prisoner-adjusted data to the other dataset\n",
    "final_join = gp.GeoDataFrame(pd.merge(pa_mod_reall_cleaned, joined_pl_data, on = \"GEOID20\", indicator = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e44f2f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_join.drop([\"_merge\", \"id_len\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de772b49",
   "metadata": {},
   "source": [
    "### Create the Aggregated Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e7319a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the files on \n",
    "old_cong = final_join.dissolve(\"CD116\", aggfunc = \"sum\")\n",
    "old_sldl = final_join.dissolve(\"SLDL18\", aggfunc = \"sum\")\n",
    "old_sldu = final_join.dissolve(\"SLDU18\", aggfunc = \"sum\")\n",
    "new_cong = final_join.dissolve(\"new_cong\", aggfunc = \"sum\")\n",
    "new_sldl = final_join.dissolve(\"new_sldl\", aggfunc = \"sum\")\n",
    "new_sldu = final_join.dissolve(\"new_sldu\", aggfunc = \"sum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201b4777",
   "metadata": {},
   "source": [
    "### Clean the Aggregated Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc680ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the columns\n",
    "def create_data_columns(df):\n",
    "    \n",
    "    # Define the voter registration columns\n",
    "    df[\"Reg_DEM\"] = df[\"party_dem\"] / df[\"total_reg\"]\n",
    "    df[\"Reg_REP\"] = df[\"party_rep\"] / df[\"total_reg\"]\n",
    "    df[\"Reg_OTH\"] = (df[\"total_reg\"]-df[\"party_dem\"]-df[\"party_rep\"]) / df[\"total_reg\"]\n",
    "    \n",
    "    # Define the demographic columns\n",
    "    df[\"Demo_ASIAN\"] = df[\"P0020008\"] / df[\"P0020001\"]\n",
    "    df[\"Demo_WHITE\"] = df[\"P0020005\"] / df[\"P0020001\"]\n",
    "    df[\"Demo_BLACK\"] = df[\"P0020006\"] / df[\"P0020001\"]\n",
    "    df[\"Demo_HISPANIC\"] = df[\"P0020002\"] / df[\"P0020001\"]\n",
    "    df[\"Demo_MIXED\"] = df[\"P0020011\"] / df[\"P0020001\"]\n",
    "    df[\"Demo_OTHER\"] = (df[\"P0020001\"] - df[\"P0020008\"] - df[\"P0020005\"] \n",
    "                        - df[\"P0020006\"] - df[\"P0020002\"] - df[\"P0020011\"])  / df[\"P0020001\"]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e3298b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the demographic columns for the adjusted data\n",
    "def create_adj_data_columns(df):\n",
    "        \n",
    "    # Define the demographic columns\n",
    "    df[\"Demo_ASIAN_adj\"] = df[\"P0020008_adj\"] / df[\"P0010001_adj\"]\n",
    "    df[\"Demo_WHITE_adj\"] = df[\"P0020005_adj\"] / df[\"P0010001_adj\"]\n",
    "    df[\"Demo_BLACK_adj\"] = df[\"P0020006_adj\"] / df[\"P0010001_adj\"]\n",
    "    df[\"Demo_HISPANIC_adj\"] = df[\"P0020002_adj\"] / df[\"P0010001_adj\"]\n",
    "    df[\"Demo_MIXED_adj\"] = df[\"P0020011_adj\"] / df[\"P0010001_adj\"]\n",
    "    df[\"Demo_OTHER_adj\"] = (df[\"P0010001_adj\"] - df[\"P0020008_adj\"] - df[\"P0020005_adj\"] \n",
    "                        - df[\"P0020006_adj\"] - df[\"P0020002_adj\"] - df[\"P0020011_adj\"])  / df[\"P0010001_adj\"]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aadd58c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_needed_columns(df):\n",
    "    return format_percentages(create_adj_data_columns(create_data_columns(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11d40b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_percentages(dataframe):\n",
    "    for col_name in [\"Reg_DEM\", \"Reg_REP\", \"Reg_OTH\", \"Demo_ASIAN\",\"Demo_WHITE\",\"Demo_BLACK\",\"Demo_HISPANIC\",\"Demo_MIXED\",\"Demo_OTHER\",\n",
    "\"Demo_ASIAN_adj\",\"Demo_WHITE_adj\",\"Demo_BLACK_adj\",\"Demo_HISPANIC_adj\",\"Demo_MIXED_adj\",\"Demo_OTHER_adj\"]:\n",
    "        dataframe[col_name] = dataframe[col_name].map('{:.1%}'.format)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e25f7a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the above functions on the six files we created\n",
    "old_cong = add_needed_columns(old_cong)\n",
    "new_cong = add_needed_columns(new_cong)\n",
    "old_sldl = add_needed_columns(old_sldl)\n",
    "new_sldl = add_needed_columns(new_sldl)\n",
    "old_sldu = add_needed_columns(old_sldu)\n",
    "new_sldu = add_needed_columns(new_sldu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21771c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
